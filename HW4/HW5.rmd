---
title: "RandomForest"
author: "Polina Kozyulina, Yulia Kondratenko, Anastasia Gainullina"
date: "May 17, 2017"
output: html_document
---
```{r libraries, message=FALSE, warning=FALSE}
library(dplyr)
library(randomForest)
library(ggplot2)

setwd('/media/polina/305622A3562269B4/bioR/RandomForest/random_forest_hw')
```

## Предподготовка данных
Читаем таблицы и готовим данные. Считаем коэффициенты корелляции для возраста и всех сайтов метилирования, и выбираем 10 наиболее значимых сайтов.

```{r data_setup, message=FALSE, warning=FALSE}

ages <- read.table("ages.tsv", sep="\t", header=1)
head(ages)

methylation <- read.table("methylation.tsv", sep="\t", header=1, row.names = 1, na.strings = "NA")
print(methylation[1:5, 1:5])

# заменяем NA на нули
methylation[is.na(methylation)] <- 0
sum(is.na(methylation))

# Подготавливаем объединенный датафрейм
methilation_age <- as.data.frame(t(methylation))
head(methilation_age[1:5, 1:5])
methilation_age <- methilation_age[-c(1, 2,3),]
methilation_age$age <- ages$Age

# Считаем корелляцию
meth <- as.matrix(methilation_age)
class(meth) <- "numeric"
cor_meth <- cor(meth[,1:95], meth[,96, drop=F])
meth <- as.data.frame(meth)
# индексы наиболее скореллированных сайтов метилирования
idx <- which(abs(cor_meth) %in% sort(abs(cor_meth), decreasing = T)[1:10])

```

## Предподготовка данных (machine learning)
Теперь делим выборку на тренировочную и валидирующую.

```{r data_split, message=FALSE, warning=FALSE}
set.seed(31)
training <- sample(1:50, 40)
validation <- (1:50)[-training]

train <- methilation_age[training, c(idx, 96)]
test <- methilation_age[validation, c(idx, 96)]

#write.table(train[, c(ncol(train), 1:(ncol(train) - 1))], "train.tsv", sep='\t', col.names = NA, quote = F)
#write.table(test[, c(ncol(test), 1:(ncol(test) - 1))], "test.tsv", sep='\t', col.names = NA, quote = F)

#train_k <- read.table("from_K/train.tsv", sep="\t", header=1, row.names = 1)
#train_p <- read.table("train.tsv", sep="\t", header = 1, row.names=1)
#train_k == train_p

head(train)
```

## Построение лесов

### Функция-обертка

```{r wrapper, message=FALSE, warning=FALSE}

wrapper <- function(train, test, runs.number=50, ...) {
  
  RMSE_n_times_train <- vector()
  RMSE_n_times_test <- vector()
  
  for (i in 1:runs.number) {
    fit.rf <- randomForest(age ~ ., data=train, ...)
    
    prediction1 <- predict(fit.rf, train)
    
    RMSE_train <- sqrt(mean((train$age - prediction1) ** 2))
    RMSE_n_times_train <- c(RMSE_n_times_train, RMSE_train)
    
    prediction2 <- predict(fit.rf, test)
    
    RMSE_test <- sqrt(mean((test$age - prediction2) ** 2))
    RMSE_n_times_test <- c(RMSE_n_times_test, RMSE_test)
    
  }
  return(c(RMSE_train = mean(RMSE_n_times_train), RMSE_test = mean(RMSE_n_times_test)))
}

```

### Тестируем функцию для разных параметров

1) Запуск randomForest с аргументами по умолчанию 50 раз и подсчет средней ошибки

```{r tests1, message=FALSE, warning=FALSE}
errors.defaults <- wrapper(train, test, 50)
print(errors.defaults)
```

2) Запуск randomForest всего с 1 деревом внутри 50 раз и подсчет средней ошибки для ntree=1 (то есть для одного дерева)

```{r tests2, message=FALSE, warning=FALSE}
errors.ntree1 <- wrapper(train, test, 50, ntree=1)
print(errors.ntree1)
```

3) Запуск randomForest со всеми вершинами (nodesize=1), replace=F, sampsize=N, mtry=M. Пример переобучения.

```{r tests3, message=FALSE, warning=FALSE}
errors.overfit <- wrapper(train, test, 50,
                          nodesize=1, replace=F, sampsize=40, mtry=10, ntree=100)
print(errors.overfit)
```

## Подбираем наилучшие параметры модели

1) __ntree__

```{r ntree, message=FALSE, warning=FALSE}
n <- seq(1, 250, 50)
testing_ntree <- sapply(n, function(x) wrapper(train, test, 
                    runs.number=50, ntree=x))

testing_ntree <- data.frame(n, t(testing_ntree))

to_plot <- data.frame(ntree = c(n, n), 
                      RMSE=c(testing_ntree$RMSE_train, testing_ntree$RMSE_test),
                      dataset=c(rep("train", 5), rep("test", 5)))


ggplot(to_plot, aes(x = ntree, y = RMSE, col=dataset)) +
  geom_line(size=2) +
  theme_bw(base_size = 14) +
  geom_vline(xintercept = 50, lty="dashed", color="cyan")

# ntree = 100

```

2) __sampsize__

```{r sampsize, message=FALSE, warning=FALSE}
sam <- seq(1, 40)

testing_replace_T <- sapply(sam, function(x) wrapper(train, test, 
                    runs.number=50, ntree=100, mtry=10, nodesize = 1, replace = T, sampsize = x))

testing_replace_F <- sapply(sam, function(x) wrapper(train, test, 
                    runs.number=50, ntree=100, mtry=10, nodesize = 1, replace = F, sampsize = x))

testing_sampsize_T <- data.frame(n, t(testing_replace_T))
testing_sampsize_F <- data.frame(n, t(testing_replace_F))

to_plot <- NULL
to_plot <- data.frame(
  sampsize=c(sam, sam, sam, sam), RMSE=c(testing_sampsize_T$RMSE_train, testing_sampsize_T$RMSE_test, testing_sampsize_F$RMSE_train, testing_sampsize_F$RMSE_test), 
  dataset=c(rep("train", length(sam)), rep("test", length(sam)), rep("train", length(sam)), rep("test", length(sam))), 
  replace=c(rep("True", 2*length(sam)), rep("False", 2*length(sam))))


ggplot(to_plot, aes(x = sampsize, y = RMSE, col=dataset, linetype=replace)) +
  geom_line(size=1) +
  theme_bw(base_size = 14) +
  geom_vline(xintercept = 5, lty="dashed", color="cyan")


# sampsize = 5, replace = True
```

3) __nodesize__

```{r nodesize, message=FALSE, warning=FALSE}
n <- seq(1, 40)
testing_nodesize <- sapply(n, function(x) wrapper(train, test, 
                    runs.number=50, ntree=100, sampsize = 5, replace = T, mtry=10, nodesize=x))

testing_nodesize <- data.frame(n, t(testing_nodesize))

to_plot <- NULL
to_plot <- data.frame(nodesize=c(n, n), RMSE=c(testing_nodesize$RMSE_train, testing_nodesize$RMSE_test), dataset=c(rep("train", max(n)), rep("test", max(n))))


ggplot(to_plot, aes(x = nodesize, y = RMSE, col=dataset)) +
  geom_line(size=2) +
  theme_bw(base_size = 14)

# nodesize 5

```

4) __mtry__

```{r mtry, message=FALSE, warning=FALSE}
n <- seq(1, 10)
testing_mtry <- sapply(n, function(x) wrapper(train, test, 
                    runs.number=50, ntree=100, sampsize = 5, replace = T, mtry=x, nodesize=5))

testing_mtry <- data.frame(n, t(testing_mtry))

to_plot <- NULL
to_plot <- data.frame(mtry=c(n, n), RMSE=c(testing_mtry$RMSE_train, testing_mtry$RMSE_test), dataset=c(rep("train", max(n)), rep("test", max(n))))


ggplot(to_plot, aes(x = mtry, y = RMSE, col=dataset)) +
  geom_line(size=2) +
  theme_bw(base_size = 14)

# mtry = 5
```

## Кросс-валидация
И вот, когда мы подобрали все параметры, надо проверить, всё ли действительно так, как кажется. И мы проводим кросс-валидацию, разбивая изначальные данные на пять выборок.

```{r cross_validation_setup, message=FALSE, warning=FALSE}

set.seed(31)

# splitting our dataset into 5 equal parts
cross.validation <- matrix(sample(1:50, 50), nrow=5, ncol=10)
cross.validation

meth_for_cross <- cbind(meth[,idx], age=meth[,96])
```

И считаем, что получилось:

```{r cross_validation, message=FALSE, warning=FALSE}

crvalid <- function(cross.validation, meth_for_cross, runs.number=100, ...){
  cross.results <- apply(cross.validation, 1, function(test.sample){
  # using each part as testing dataset
  train.sample <- (1:50)[-test.sample]
  train <- meth_for_cross[train.sample, ]
  
  # using rest of the dataset as training dataset
  test <- meth_for_cross[test.sample, ]
  
  # calculating RMSE for every part and default random forest
  return(wrapper(train, test, runs.number, ...))
})
  return(rowMeans(cross.results))
}

```

## Результаты кросс-валидации
Модель работает, только результаты параметров randomForest по умолчанию срабатывают лучше, чем подобранные вручную.

```{r answer, message=FALSE, warning=FALSE}
# Default
print(crvalid(cross.validation, meth_for_cross))

# Set
print(crvalid(cross.validation, meth_for_cross, ntree=100, sampsize = 5, replace = T, mtry=3, nodesize=5))

```

